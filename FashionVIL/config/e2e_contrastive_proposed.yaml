# FashionGen data nums: 60147

includes:
- configs/models/fashionvil/defaults.yaml

dataset_config:
  fashiongen:
    use_images: true
    use_features: false

model_config:
  fashionvil:
    image_encoder:
      type: torchvision_resnet
      params:
        name: resnet50
        pretrained: true
        zero_init_residual: false
        num_output_features: -1
        pool_type: avg
    lr_multiplier: 20
    direct_features_input: false
    bert_model_name: bert-base-uncased
    training_head_type: contrastive
    bypass_transformer: true
    losses:
      - type: contrastive_loss

scheduler:
  type: multi_step
  params:
    use_warmup: true
    lr_steps:
    - 28170
    - 56340
    lr_ratio: 0.1
    warmup_iterations: 260
    warmup_factor: 0.25

optimizer:
  type: adam_w
  params:
    lr: 1e-5
    eps: 1e-8
    weight_decay: 1e-4

evaluation:
  metrics:
    - r@k_kaleido

training:
  experiment_name: globallocal_1e5_1e4_drop07_subimg_l # fashionvil_contrastive_fashiongen_e2e_pretrain_final
  batch_size: 100 # 32
  lr_scheduler: true
  max_updates: 2600 # 1800 # 2600 # 3100 # 12080
  log_interval: 10
  checkpoint_interval: 260
  evaluation_interval: 260
  early_stop:
    criteria: fashiongen/r@k_general/avg
    minimize: false
  wandb:
    enabled: false

run_type: train # test

checkpoint:
  resume_pretrained: true
  resume_file: save/fashionvil_e2e_pretrain_final/fashionvil_final.pth
  pretrained_state_mapping:
    # image_encoder_g: image_encoder
    # image_encoder_l: image_encoder
    # model.bert: model.bert
    image_encoder_g: image_encoder_g
    image_encoder_l: image_encoder_l
    model.bert: model.bert
    # model.img_combiner: model.img_combiner
    # model.txt_combiner: model.txt_combiner
